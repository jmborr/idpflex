{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Example\n",
    "\n",
    "In this example we cluster a short trajectory (1000 frames) of the disordered peptide [hiAPP](https://www.ncbi.nlm.nih.gov/pubmed/24021023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import MDAnalysis as mda\n",
    "import nglview\n",
    "from tqdm import tqdm\n",
    "import pathos\n",
    "import multiprocessing\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "from idpflex.cnextend import load_tree\n",
    "from idpflex.cluster import cluster_trajectory\n",
    "from idpflex.properties import (SaxsProperty, SecondaryStructureProperty, ResidueContactMap,\n",
    "                                propagator_size_weighted_sum)\n",
    "from idpflex.utils import write_frame\n",
    "from idpflex.bayes import fit_to_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Donwload Data\n",
    "\n",
    "It's assumed <code>git</code> is installed in your system. Otherwise,\n",
    "[follow instructions](http://idpflex.readthedocs.io/en/latest/installation.html#testing-tutorials-data)\n",
    "to download and unpack your data to <code>/tmp/idpflex_data</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "idpflex_data_dir=\"/tmp/idpflex_data\"\n",
    "git clone https://github.com/jmborr/idpflex_data ${idpflex_data_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idpflex_data_dir = '/tmp/idpflex_data'\n",
    "data_dir = os.path.join(idpflex_data_dir, 'data', 'simulation')\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "simulation = mda.Universe(os.path.join(data_dir, 'hiAPP.pdb'),\n",
    "                          os.path.join(data_dir, 'hiAPP.xtc'))\n",
    "print('Number of frames in trajectory is ', simulation.trajectory.n_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Trajectory Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w_show = nglview.show_mdanalysis(simulation)\n",
    "w_show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "We cluster the trajectory in two steps:\n",
    "1. cluster the 1000 frames into 100 small clusters, producing 100 representative structures\n",
    "2. cluster all 100 representative structures in a hierarchichal tree.\n",
    "\n",
    "The first step will be obtained by splicing the trajectory into segments of 100 frames, and obtaining 10 representatives for each segment. Thus, we obtain a total of 100 representatives. See [clustering](http://idpflex.readthedocs.io/en/latest/idpflex/cluster.html) for more info.\n",
    "\n",
    "The two steps process makes more sense with large trajectories, for instance, a trajectory of $10^5$ frames that we cluster into 1000 representatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cl = cluster_trajectory(simulation, segment_length=100, n_representatives=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick View of the Clustering Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('RMSD (Angstroms)')\n",
    "dendrogram(cl.tree.z,\n",
    "           #truncate_mode='lastp',  # show only the last p merged clusters\n",
    "           #p=20,  # show this many cluster at the bottom of the tree\n",
    "           show_leaf_counts=False,  # otherwise numbers in brackets are counts\n",
    "           leaf_rotation=90.,\n",
    "           leaf_font_size=12.,\n",
    "           show_contracted=True,  # to get a distribution impression in truncated branches\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract PDB Files for Representative Structures\n",
    "We extract PDB files for each of the 100 representatives and store under directory `/tmp/PDB`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_names = ['/tmp/PDB/conf_{}.pdb'.format(idx) for idx in cl.idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subprocess.call(['mkdir', '-p', '/tmp/PDB'])  # directory to store the PDB files\n",
    "for idx, name in tqdm(list(zip(cl.idx, pdb_names))):\n",
    "    write_frame(simulation, idx, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of X-Ray Profiles with CRYSOL\n",
    "\n",
    "It is assumed that `crysol` is installed in your computer. We store a profile for each representative in directory `/tmp/CRYSOL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pool = pathos.pools.ProcessPool(processes=multiprocessing.cpu_count())\n",
    "profiles = list(tqdm(pool.map(SaxsProperty().from_crysol_pdb, pdb_names), total=len(pdb_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the profiles for the 100 representatives, we can calculate the X-ray profiles for any node of the hierarchical tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crysol_names = ['/tmp/CRYSOL/conf_{}.int'.format(idx) for idx in cl.idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[profile.to_ascii(name) for profile, name in zip(profiles, crysol_names)]\n",
    "propagator_size_weighted_sum(profiles, cl.tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Experimental\" X-Ray profile\n",
    "\n",
    "We do not have an experimental profile], so we are going to create a fake experimental profile using the profiles from some of the nodes. The task for the fit engine will be to identify which nodes did we use.\n",
    "\n",
    "Starting from the top of the tree (the root node), we will descend to `level=6`, which contains 7 nodes (the first level is the root node corresponding to `level=0`) We will assign different weights to each of the seven profiles and construct our profile with these weigths.\n",
    "\n",
    "The profile will be stored as a [SAXS property](http://idpflex.readthedocs.io/en/latest/idpflex/properties.html#idpflex.properties.SaxsProperty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nodes = cl.tree.nodes_at_depth(6)\n",
    "weights = [0.00, 0.13, 0.0, 0.55, 0.0, 0.32, 0.00]  # the weights add up to one\n",
    "# x are the Q-values\n",
    "x = nodes[0]['saxs'].x\n",
    "# y are the intensities\n",
    "y = weights[0] * nodes[0]['saxs'].y\n",
    "for i, node in enumerate(nodes[1:]):\n",
    "    y += weights[i] * node['saxs'].y\n",
    "# Errors simple taken as 10% of the intensities\n",
    "e = y * 0.1\n",
    "# Now we create our X-Ray property\n",
    "exp_saxs = SaxsProperty(qvalues=x, profile=y, errors=e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can plot the property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(exp_saxs.x, exp_saxs.y)\n",
    "ax.set_xlabel('Q', size=25)\n",
    "ax.set_ylabel('Intensity', size=25)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Tree Against the Experimental Profile\n",
    "\n",
    "Starting from the root node, we fit each tree level against the experimental profile, up to a maximum depth (in this case, `level=12`. Then we will inquire the goodnes of fit for each level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fits = fit_to_depth(cl.tree, exp_saxs, exp_saxs.name, max_depth=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fits` is a list of [ModelResult](https://lmfit.github.io/lmfit-py/model.html#lmfit.model.ModelResult) instances, one result for every level. We extract the goodness of fit `\\chi^2` and plot versus level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chi2 = [fit.redchi for fit in fits]\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('level', size=25)\n",
    "ax.set_ylabel('Chi-squared', size=25)\n",
    "ax.set_yscale('log')\n",
    "ax.plot(chi2)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the steep drop in orders of magnitude for $\\chi^2$ at `level=6` indicates the fit engine successfully fitted the experimental profile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the Tree Level with Best Fit to Experimental Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_fit = fits[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight of Each Cluster\n",
    "We inquire the weight that the fit engine assigned to each of the seven clusters of `level=6`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key in best_fit.best_values:\n",
    "    if 'amplitude' in key:\n",
    "        print(key, '{:4.2f}'.format(best_fit.best_values[key]))\n",
    "print(['{:4.2f}'.format(x) for x in weights])  # weights used to construct the experimental profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The order in which the fitted weights are printed is different that the order of the experimental weight. Object `best_fit.best_values` is a python dictionary and order is not guaranteed for this type of object. However, we can use the node id in the amplitude name to sort the fitted weights from smaller to higher node id.\n",
    "\n",
    "The fit procedure correctly identified that only three out of the seven nodes are contributing to the experimental profile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representative Structures of the Nodes\n",
    "Find a representative structure for each of the three nodes contributing to the match of the experimental profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "node_ids = [188, 190, 192]  # ID's for the clusters matching the experimental profile \n",
    "leafs = [cl.tree[id].representative(cl.rmsd) for id in node_ids]\n",
    "repr_names = [pdb_names[l.id] for l in leafs]  # representative structures for each node\n",
    "print(repr_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "view = nglview.show_file(repr_names[0])\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "view = nglview.show_file(repr_names[1])\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "view = nglview.show_file(repr_names[2])\n",
    "view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of PDB Structures for each Cluster\n",
    "\n",
    "We are interested to know which PDB structures comprise each of the three clusters contributing to the fit. Each cluster is made up of a number of mini-centroids, and each mini-centroid has associated a PDB file stored in list `pdb_names`.\n",
    "\n",
    "We create a file for each of our three clusters, with path `/tmp/node{X}_pdblist.txt` where `{X}` stands up for cluster ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_ids = [188, 190, 192]  # ID's for the clusters matching the experimental profile \n",
    "for id in node_ids:\n",
    "    pdb_list = [pdb_names[leaf_id] for leaf_id in cl.tree[id].leaf_ids]\n",
    "    open('/tmp/node{}_pdblist.txt'.format(id), 'w').write('\\n'.join(pdb_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secondary Structure Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Secondary Structure for Nodes of the Tree\n",
    "\n",
    "It is neccessary to have DSSP executable in your machine. The default name for the executable is `mkdssp`.\n",
    "\n",
    "We start by calculating the DSSP profile for each of the 100 representatives using their PDB files. After that we calculate the DSSP profile for the rest of nodes in the tree using the\n",
    "[propagator](http://idpflex.readthedocs.io/en/latest/idpflex/properties.html#idpflex.properties.propagator_size_weighted_sum)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ss_profiles = [SecondaryStructureProperty().from_dssp_pdb(name, command='mkdssp') for name in pdb_names]\n",
    "propagator_size_weighted_sum(ss_profiles, cl.tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Secondary Structure Content for Matching Nodes\n",
    "We are interested in the three nodes contributing to the fit of the experimental profile. We plot how much secondary structure each node contains\n",
    "\n",
    "| Index | DSSP | Color |        Structure             |\n",
    "|-------|------|-------|------------------------------|\n",
    "|   0   |  H   |yellow | Alpha helix (4-12)           |\n",
    "|   1   |  B   | pink  | Isolated beta-bridge residue |\n",
    "|   2   |  E   | red   | Strand                       |\n",
    "|   3   |  G   |orange | 3-10 helix                   | \n",
    "|   4   |  I   | green | Pi helix                     |\n",
    "|   5   |  T   |magenta| Turn                         |\n",
    "|   6   |  S   | cyan  | Bend                         |\n",
    "|   7   |      | white |Unstructured (coil)           |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "node_ids = [188, 190, 192]  # ID's for the clusters matching the experimental profile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[cl.tree[id]['ss'].plot(kind='percents') for id in node_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Secondary Structure Probabilities of Matching Nodes\n",
    "\n",
    "Each node is actually a cluster or ensemble of structures, out of the 100 representative structures. Thus for a given node, each residue has a certain probability to be in one of the different DSSP states.\n",
    "\n",
    "| Index | DSSP | Color |        Structure             |\n",
    "|-------|------|-------|------------------------------|\n",
    "|   0   |  H   |yellow | Alpha helix (4-12)           |\n",
    "|   1   |  B   | pink  | Isolated beta-bridge residue |\n",
    "|   2   |  E   | red   | Strand                       |\n",
    "|   3   |  G   |orange | 3-10 helix                   | \n",
    "|   4   |  I   | green | Pi helix                     |\n",
    "|   5   |  T   |magenta| Turn                         |\n",
    "|   6   |  S   | cyan  | Bend                         |\n",
    "|   7   |      | white |Unstructured (coil)           |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[cl.tree[id]['ss'].plot(kind='node') for id in node_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Secondary Structure of Matching Nodes\n",
    "\n",
    "Each node is actually a cluster or ensemble of structures, out of the 100 representative structures. Thus for a given node we can plot the secondary structure of each structure belonging to the node\n",
    "\n",
    "| Index | DSSP | Color |        Structure             |\n",
    "|-------|------|-------|------------------------------|\n",
    "|   0   |  H   |yellow | Alpha helix (4-12)           |\n",
    "|   1   |  B   | pink  | Isolated beta-bridge residue |\n",
    "|   2   |  E   | red   | Strand                       |\n",
    "|   3   |  G   |orange | 3-10 helix                   | \n",
    "|   4   |  I   | green | Pi helix                     |\n",
    "|   5   |  T   |magenta| Turn                         |\n",
    "|   6   |  S   | cyan  | Bend                         |\n",
    "|   7   |      | white |Unstructured (coil)           |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[cl.tree[id]['ss'].plot(kind='leafs') for id in node_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residue Contact Map\n",
    "We start by calculating the residue contact map property for each of the 100 representatives, and then propagate the maps up the tree, as usual. Here we deem two residues in contact if any of its two atoms are less than 4.0 Angstroms apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "maps = [ResidueContactMap().from_pdb(name, 4.0) for name in tqdm(pdb_names)]\n",
    "propagator_size_weighted_sum(maps, cl.tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to calculate the residue contact maps using only the CA atoms with a 6 Angstroms cut off, the we would write:\n",
    "```\n",
    "maps = [ResidueContactMap().from_PDB(name, 6.0, selection='name CA') for name in pdb_names]\n",
    "```\n",
    "\n",
    "After calculation of the maps and propagation up the tree, we proceed to plot the map for the three nodes identified during the fittin procedure agains our \"experimental\" profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[cl.tree[id]['cm'].plot() for id in node_ids]  # The name of the residue contact map property is 'cm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the State of the Tree\n",
    "We've done a few things! We can save the hiearchical tree along with the calculated properties so that later we can continue our work withougt having to redo the clustering or recalculate the properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sys.setrecursionlimit(10000)\n",
    "cl.save('/tmp/hiAPP.pck')  # save the tree and properties to a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next time we don't need to recalculate the properties. We can load the saved tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_of_tree = load_tree('/tmp/hiAPP.pck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we can use this tree, for instance, to plot the secondary structure of the third cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = node_ids[2]  # id of the third cluster\n",
    "copy_of_tree.tree[id]['ss'].plot(kind='node')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
